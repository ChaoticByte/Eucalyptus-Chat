llama-cpp-python[server]==0.1.48
uvicorn==0.22.0
sanic==23.3.0