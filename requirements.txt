llama-cpp-python[server]==0.1.54
uvicorn==0.22.0
sanic==23.3.0