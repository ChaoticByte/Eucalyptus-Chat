llama-cpp-python[server]==0.1.53
uvicorn==0.22.0
sanic==23.3.0